# TradeSense AI

**Production-ready, real-time trading insight platform** â€” an end-to-end system combining streaming data ingestion, asynchronous processing, RAG-powered LLM analysis, and cloud-native deployment on AWS. This repository is designed to demonstrate advanced backend engineering, DevOps, and LLM integration skills.

---

## ğŸš€ Project Overview

TradeSense AI captures live market data, computes analytics, and generates human-readable trade opportunities and summaries using Retrieval-Augmented Generation (RAG) with LLMs. The system is event-driven, scalable, and hardened for production use.

Primary goals:

- Build a production-grade system that can be hosted on AWS (free-tier conscious)
- Showcase skills: FastAPI, Django (admin), MongoDB, Postgres (RDS), Redis, Celery, RabbitMQ, AWS (EC2, Lambda, API Gateway, S3), Kubernetes, ArgoCD, Jenkins, encryption, and LLM/RAG
- Maintain weekly public progress updates for portfolio and LinkedIn
- Learn deeply by implementing, deploying, and monitoring each component

---

## ğŸ§© Key Features

- Live market data ingestion (WebSocket / REST polling)
- Real-time analytics and alerting (Celery workers)
- LLM + RAG for AI-driven trade summaries and Q&A
- Secure storage (AES-256) for sensitive data
- CI/CD pipeline (Jenkins + ArgoCD) and GitOps deployment
- Monitoring (CloudWatch / Prometheus + Grafana) and logs
- Dev/prod parity with Docker, minikube/kind (local), and AWS deployment

---

## ğŸ“¦ Tech Stack

**Backend:** FastAPI (microservices), Django (admin)

**Datastores:** MongoDB (document + vector), PostgreSQL (RDS), Redis (cache / vector), S3-compatible storage

**Messaging & Workers:** RabbitMQ (broker), Celery (tasks)

**AI / LLM:** Ollama (local) or Gemini/OpenAI (cloud), FAISS/Chroma/Redis-Vector for embeddings

**Infra & DevOps:** Docker, Kubernetes (minikube/kind or EKS), ArgoCD, Jenkins, Terraform (optional), LocalStack (for offline AWS emulation)

**Security:** JWT, AES-256 encryption, AWS KMS (optional)

**Monitoring:** Prometheus, Grafana, CloudWatch

---

## ğŸ“ Repository Structure (Suggested)

```
tradesense-ai/
â”œâ”€â”€ infra/                  # Terraform / ArgoCD manifests / Kubernetes charts
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ api/                # FastAPI service: ingestion, query endpoints
â”‚   â”œâ”€â”€ analytics/          # Celery tasks, aggregations
â”‚   â”œâ”€â”€ ai-insight/         # RAG + LLM orchestration (can be a Lambda-compatible service)
â”‚   â”œâ”€â”€ admin/              # Django admin dashboard
â”‚   â””â”€â”€ alerting/           # Notification microservice (email/Slack)
â”œâ”€â”€ docs/                   # Architecture diagrams, runbooks, designs
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ k8s/                    # Kubernetes manifests for minikube / EKS
â”œâ”€â”€ Jenkinsfile
â”œâ”€â”€ README.md
â””â”€â”€ scripts/                # helper scripts (db init, data loaders)
```

---

## ğŸ”§ Quickstart â€” Local Development (Phase 1)

> Goal: Run the core services locally with Docker Compose: FastAPI, MongoDB, PostgreSQL, RabbitMQ, Redis, Celery worker.

1. Clone repository:

```bash
git clone https://github.com/<your-user>/tradesense-ai.git
cd tradesense-ai
```

2. Copy env template and adjust values:

```bash
cp .env.example .env
# edit .env to set SERVICE_PORTS, DB creds, LLM settings, JWT secret
```

3. Start services with Docker Compose:

```bash
docker-compose up --build
```

4. Initialize databases (scripts/db_init.sh) â€” run migrations and ensure Mongo indexes for embeddings.

5. Load sample market data (scripts/load_sample_data.py) to simulate live stream.

6. Access the API:

- FastAPI docs: `http://localhost:8000/docs`
- Django admin: `http://localhost:8001/admin` (create superuser via `scripts/create_admin.sh`)

---

## ğŸ› ï¸ Phase 1 â€” Deliverables

- FastAPI service(s): `/ingest`, `/query`, `/health`
- Celery + RabbitMQ worker for background tasks (embedding generation, analytics)
- MongoDB schema & vector index setup
- Postgres schema for users, subscriptions, alerts
- Basic LLM + RAG integration (local Ollama or remote API key configurable)
- Docker Compose for local orchestration
- Unit tests for core logic and CI integration stub

---

## â˜ï¸ Phase 2 â€” AWS Deployment (Free-tier mindful)

- EC2: fastapi + celery workers (t2.micro/t3.micro) or EKS for Kubernetes
- RDS: PostgreSQL (free-tier instance)
- MongoDB Atlas free-tier cluster
- S3: document storage and raw data
- Lambda + API Gateway: summary generator and lightweight endpoints
- CloudWatch: logs and basic metrics
- IAM roles and KMS for secrets

Security considerations and costs are in `docs/aws_cost_and_security.md`.

---

## ğŸ” CI/CD & GitOps

- Jenkins pipeline builds Docker images and runs tests
- Push to private Docker registry (or GitHub Container Registry)
- ArgoCD watches repo and deploys to Kubernetes (minikube for local demo; EKS for prod)
- Optional: GitHub Actions can replace Jenkins for a zero-infra CI

---

## ğŸ” Security & Ops

- Use JWT for API auth, with refresh tokens
- AES-256 for sensitive data at rest; keys managed via AWS KMS in prod
- Environment variables stored via AWS SSM / Secrets Manager in production
- Rate limiting using FastAPI middleware (limits per IP/api-key)
- Audit logs written to Postgres and S3

---

## ğŸ“ˆ Observability & Monitoring

- Expose Prometheus metrics in each service (`/metrics`)
- Grafana dashboards for latency, error rates, task queue depth
- CloudWatch for AWS-hosted components
- Alerts via SNS / Slack webhook on failures or high queue depth

---

## ğŸ“ Weekly Update Template (for LinkedIn)

**Week X â€” TradeSense AI Update**

- What I built this week: _short summary_
- Key learnings: _what new tech / pitfalls_
- Screenshot or GIF: _API response, Grafana panel, deployment log_
- Link to repo: `https://github.com/<your-user>/tradesense-ai`

---

## âœ… Demo Script (for interviews)

1. Briefly present architecture diagram (docs/arch.png)
2. Show `docker-compose up` bringing services online
3. Run `scripts/load_sample_data.py` to simulate live feed
4. Query `/query` endpoint to generate an AI summary (show logs)
5. Show Celery dashboard/Flower or metrics for background tasks
6. Show Jenkins pipeline run or ArgoCD sync
7. Discuss how you would scale this to handle production traffic

---

## ğŸ™Œ Contributing

Contributions, issues, and feature requests are welcome. Please read `CONTRIBUTING.md` for details on coding standards and local setup.

---

## ğŸ“„ License

MIT License â€” see `LICENSE` file.

---

## ğŸ“ Contact

Your Name â€” `your.email@example.com` | GitHub: `https://github.com/<your-user>` | LinkedIn: `https://linkedin.com/in/<your-user>`

---

_End of README â€” Proceed to Phase 1 scaffolding when ready._
